{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30c23491",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1034917c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wget in c:\\users\\hp\\anaconda3\\envs\\textmining\\lib\\site-packages (3.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.optim import AdamW\n",
    "\n",
    "%pip install wget\n",
    "\n",
    "from transformers import SentimentTransformer\n",
    "from utils import enwik8, train_model, test_model, create_sentence_batches, load_imdb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2c5036",
   "metadata": {},
   "source": [
    "# Get Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48afffde",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "x_train, x_val: List[List[int]] -> integer encoded sentences\n",
    "y_train, y_val: List[int] -> labels for each sentence\n",
    "i2w -> int to word mapping\n",
    "w2i -> word to int mapping\n",
    "numcls -> Number of labels\n",
    "\"\"\"\n",
    "(x_train, y_train), (x_val, y_val), (i2w, w2i), numcls = load_imdb(final=False)\n",
    "path = r\"C:\\Users\\Hp\\Desktop\\Coding\\Thesis\\enwik8 (1).gz\"\n",
    "wiki_data = enwik8(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eb2e6c94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5000000])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_data[2].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b358f3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_batch(data, seq_len, batch_size):\n",
    "    \"\"\" Breaks down a sequence of chars into a batch of subsequences of chars.\n",
    "    :return: batch of input sequences for the model and corresponding target sequences shifted by 1 char.\n",
    "    \"\"\"\n",
    "    # randomly select batch_size no. of starting points for seqs in the batch\n",
    "    start_pts = torch.randint(size=batch_size, low=0, high=data.size(0) - seq_len - 1)\n",
    "    inputs, targets = [], []\n",
    "    for st in start_pts:\n",
    "        input = data[st : st + seq_len]\n",
    "        target = data[st + 1 : st + seq_len + 1]        \n",
    "        inputs.append(input[None, :])\n",
    "        targets.append(target[None, :])\n",
    "\n",
    "    inputs = torch.cat(inputs, dim=0).to(torch.long)\n",
    "    targets = torch.cat(targets, dim=0).to(torch.long)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b3dc94",
   "metadata": {},
   "source": [
    "# Model Initialisation and Batch Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6c4fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating batches\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size = 32\n",
    "train_batches = create_sentence_batches(x_train, y_train, batch_size=32, device=device)\n",
    "val_batches = create_sentence_batches(x_val, y_val, batch_size=32, device=device)\n",
    "\n",
    "# model init\n",
    "embedding_dim = 300\n",
    "vocab_size = len(w2i)\n",
    "model = SentimentTransformer(embedding_dim, vocab_size, numcls, heads=1, num_encoders=1, mask=True).to(device)\n",
    "\n",
    "# model training\n",
    "epochs = 10\n",
    "learning_rate = 0.001\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "# train_model(train_batches, model, optimizer, learning_rate=learning_rate, epochs=epochs, print_progress=True)\n",
    "\n",
    "# model testing\n",
    "# test_model(val_batches, model, print_metrics=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "textMining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
