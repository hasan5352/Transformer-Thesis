{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b9956ac",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8417b41c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import timm\n",
    "\n",
    "from my_transformers import CorruptDistillVisionTransformer\n",
    "from utils import load_experimental_TinyImageNet\n",
    "from train_test_module import compute_ece\n",
    "import json\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38b26182",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainTestBaseline:\n",
    "    def __init__(self, model:nn.Module, train_loader, test_loader,\n",
    "                 num_img_types, batch_size, device\n",
    "                 ):\n",
    "        self.model = model.to(device)\n",
    "        self.train_loader = train_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.num_img_types = num_img_types\n",
    "        self.device = device\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        for param in model.parameters(): param.requires_grad = False\n",
    "        for param in model.head.parameters(): param.requires_grad = True\n",
    "\n",
    "        self.all_test_metrics, self.all_train_metrics = [], []\n",
    "\n",
    "    def test(self, print_metrics=False):\n",
    "        top1_correct_preds, top5_correct_preds = 0, 0\n",
    "        total_samples, total_ece, total_entropy = 0, 0, 0\n",
    "\n",
    "        total_per_type = torch.zeros(self.num_img_types, device=self.device)\n",
    "        top1_correct_per_type = torch.zeros(self.num_img_types, device=self.device)\n",
    "        top5_correct_per_type = torch.zeros(self.num_img_types, device=self.device)\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for x_batch, y_batch, c_batch in self.test_loader:\n",
    "                x_batch, y_batch, c_batch = x_batch.to(self.device), y_batch.to(self.device), c_batch.to(self.device)\n",
    "                x_batch = F.interpolate(x_batch, size=(224, 224), mode='bilinear', align_corners=False)\n",
    "                preds = self.model(x_batch)\n",
    "                del x_batch \n",
    "                \n",
    "                total_samples += y_batch.size(0)\n",
    "                # top-1 acc\n",
    "                top1_right = (torch.argmax(preds, dim=1) == y_batch)\n",
    "                top1_correct_preds += top1_right.sum().item()\n",
    "                # top-5 acc\n",
    "                top5_right = torch.topk(preds, 5, dim=1).indices.eq(y_batch.unsqueeze(1)).any(dim=1)\n",
    "                top5_correct_preds += top5_right.sum().item()\n",
    "                # ECE loss\n",
    "                total_ece += compute_ece(preds, y_batch, self.device)\n",
    "                # Per-type acc\n",
    "                for t in range(self.num_img_types):\n",
    "                    mask = (c_batch == t)\n",
    "                    total_per_type[t] += mask.sum()\n",
    "                    top1_correct_per_type[t] += top1_right[mask].sum()\n",
    "                    top5_correct_per_type[t] += top5_right[mask].sum()\n",
    "                # entropy\n",
    "                total_entropy += -torch.sum(torch.softmax(preds, dim=1) * torch.log_softmax(preds, dim=1), dim=1).sum().item()\n",
    "                del y_batch, c_batch\n",
    "                \n",
    "        top1_acc_per_type = (top1_correct_per_type / total_per_type).tolist()\n",
    "        test_metrics = {\n",
    "            \"top1_acc\" : top1_correct_preds / total_samples, \n",
    "            \"top5_acc\" : top5_correct_preds / total_samples, \n",
    "            \"top1_acc_per_type\" : top1_acc_per_type,\n",
    "            \"top5_acc_per_type\" :(top5_correct_per_type / total_per_type).tolist(), \n",
    "            \"error_rate_per_type\" : [1 - acc for acc in top1_acc_per_type],\n",
    "            \"ece\" : total_ece / total_samples,\n",
    "            \"entropy\" : total_entropy / total_samples\n",
    "        }\n",
    "        if print_metrics : print(f\"Test-Accuracy:{test_metrics['top1_acc']:.2f}\")\n",
    "        return test_metrics\n",
    "    \n",
    "    def train(self, optimizer, scheduler, augmenter, save_path, \n",
    "              num_epochs=1, label_smoothing=0.1, erasing_p=0, print_metrics=False\n",
    "              ):\n",
    "        erase = T.RandomErasing(p=erasing_p)\n",
    "        mean = torch.tensor([0.485, 0.456, 0.406], device=self.device).view(1, 3, 1, 1)\n",
    "        std  = torch.tensor([0.229, 0.224, 0.225], device=self.device).view(1, 3, 1, 1)\n",
    "        best_acc, epochs_no_improve, min_delta, patience = 0, 0, 0.003, 5\n",
    "\n",
    "        for epoch in range(1, num_epochs+1):\n",
    "            self.model.train()\n",
    "            print(f\"------- Epoch {epoch} -------\")\n",
    "            total_samples, top1_correct_preds, loss_total = 0, 0, 0\n",
    "\n",
    "            for x_batch, y_batch, _ in self.train_loader:\n",
    "                x_batch, y_batch = x_batch.to(self.device), y_batch.to(self.device)\n",
    "                x_batch, y_batch = augmenter(x_batch, y_batch)\n",
    "                x_batch = F.interpolate(x_batch, size=(224, 224), mode='bilinear', align_corners=False)\n",
    "                x_batch = (x_batch - mean) / std\n",
    "                x_batch = torch.stack([erase(img) for img in x_batch])\n",
    "                preds = self.model(x_batch)\n",
    "\n",
    "                del x_batch                 # free memory\n",
    "                total_samples += y_batch.size(0)\n",
    "                # top-1 acc.  # if coming from mixup/cutmix\n",
    "                if len(y_batch.shape)==2 : top1_correct_preds += (torch.argmax(preds, dim=1) == torch.argmax(y_batch, dim=-1)).sum().item()\n",
    "                else : top1_correct_preds += (torch.argmax(preds, dim=1) == y_batch).sum().item()\n",
    "                #loss   # ybatch can be passed in directly even if cutmix/mixup applied\n",
    "                loss = F.cross_entropy(preds, y_batch, label_smoothing=label_smoothing)\n",
    "                # backprop\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                scheduler.step() \n",
    "\n",
    "                loss_total += loss.item() * y_batch.size(0)\n",
    "                del y_batch, preds, loss            # free memory\n",
    "\n",
    "            test_metrics = self.test()\n",
    "            train_metrics = {\n",
    "                \"loss_total\": loss_total/total_samples,\n",
    "                \"top1_acc\" : top1_correct_preds / total_samples\n",
    "                }\n",
    "            current_acc = test_metrics['top1_acc']\n",
    "            if print_metrics : \n",
    "                print(f\"train-loss: {train_metrics['loss_total']:.2f} -- train-acc: {train_metrics['top1_acc']:.2f} -- \"\n",
    "                      f\"test-acc: {current_acc:.2f}\"\n",
    "                      )\n",
    "            self.all_train_metrics.append(train_metrics)\n",
    "            self.all_test_metrics.append(test_metrics)\n",
    "\n",
    "            # early stopping\n",
    "            if current_acc - best_acc > min_delta:\n",
    "                best_acc = current_acc\n",
    "                epochs_no_improve = 0\n",
    "            else:\n",
    "                epochs_no_improve += 1\n",
    "\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch} â€” no improvement in {patience} epochs.\")\n",
    "                break\n",
    "        \n",
    "        # save trained model and metrics\n",
    "        if save_path:\n",
    "            torch.save(self.model.state_dict(), f\"{save_path}.pth\")\n",
    "            print(f\"Model saved to {save_path}\")\n",
    "            \n",
    "            with open(f\"{save_path}_train_metrics.json\", \"w\") as f1:\n",
    "                json.dump(self.all_train_metrics, f1, indent=4)\n",
    "            with open(f\"{save_path}_test_metrics.json\", \"w\") as f2:\n",
    "                json.dump(self.all_test_metrics, f2, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c890196",
   "metadata": {},
   "source": [
    "# ------------------- Template --------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5f51e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting seed \n",
    "torch.cuda.manual_seed(22)\n",
    "random.seed(22)\n",
    "torch.manual_seed(22)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "corrupt_types = [\"motion_blur\", \"shot_noise\", \"jpeg_compression\", \"fog\"]\n",
    "\n",
    "# Hyper-parameters\n",
    "NUM_IMG_TYPES = len(corrupt_types)+1\n",
    "NUM_CLASSES = 200\n",
    "DROPOUT = 0\n",
    "DROP_PATH = 0.1\n",
    "\n",
    "ERASE_P = 0.25\n",
    "RANDAUG_P = 0.5\n",
    "MIXUP_P = 0.8\n",
    "CUTMIX_P = 1\n",
    "AUGMIX_P = 0\n",
    "\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "NUM_EPOCHS = 50\n",
    "WARMUP_EPOCHS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a392cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=TensorDataset(*torch.load(\"train_data.pt\", weights_only=True)), \n",
    "                                 batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=TensorDataset(*torch.load(\"test_data.pt\", weights_only=True)), \n",
    "                                 batch_size=BATCH_SIZE, shuffle=False)\n",
    "# itr = iter(test_loader)\n",
    "# train_batch = [next(itr)]\n",
    "# test_batch = [next(itr)]\n",
    "\n",
    "# deit3_small_patch16_224.fb_in22k_ft_in1k -- 22M\n",
    "deit3_small = timm.create_model('deit3_small_patch16_224.fb_in22k_ft_in1k', pretrained=True).cuda()\n",
    "deit3_small.head = nn.Linear(in_features=384, out_features=NUM_CLASSES, bias=True).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40520ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timm.models.layers import DropPath\n",
    "def set_drop_path(model, drop_path):\n",
    "    for i in range(len(model.blocks)):\n",
    "        model.blocks[i].drop_path1 = DropPath(drop_path) if drop_path > 0 else nn.Identity()\n",
    "        model.blocks[i].drop_path2 = DropPath(drop_path) if drop_path > 0 else nn.Identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4afdbbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === LR Scheduler ===\n",
    "total_steps = NUM_EPOCHS * len(train_loader)\n",
    "warmup_steps = WARMUP_EPOCHS * len(train_loader)\n",
    "\n",
    "learning_rates = [5e-5, 1e-5, 5e-6]\n",
    "optimizer = optim.AdamW(deit3_small.parameters(), lr=5e-4, weight_decay=0.03)\n",
    "warmup_scheduler = optim.lr_scheduler.LinearLR(optimizer, start_factor=1e-5, total_iters=warmup_steps)\n",
    "lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS-WARMUP_EPOCHS)\n",
    "scheduler = optim.lr_scheduler.SequentialLR(\n",
    "    optimizer, schedulers=[warmup_scheduler, lr_scheduler], milestones=[warmup_steps]\n",
    ")\n",
    "\n",
    "from train_test_module import MyAugments\n",
    "augmenter = MyAugments(NUM_CLASSES) # , mixup_p=MIXUP_P, randaug_p=RANDAUG_P, cutmix_p=CUTMIX_P, augmix_p=AUGMIX_P"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdab604",
   "metadata": {},
   "source": [
    "# Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80401a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Epoch 1 -------\n",
      "train-loss: 4.73 -- train-acc: 0.19 -- test-acc: 0.41\n",
      "------- Epoch 2 -------\n"
     ]
    }
   ],
   "source": [
    "baseline_module = TrainTestBaseline(deit3_small, train_loader, test_loader, NUM_IMG_TYPES, BATCH_SIZE, device)\n",
    "baseline_module.train(optimizer, scheduler, augmenter, \"deit3-ex1\", num_epochs=NUM_EPOCHS, erasing_p=ERASE_P, print_metrics=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01eb6d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'top1_acc': 0.49425,\n",
       " 'top5_acc': 0.6808,\n",
       " 'top1_acc_per_type': [0.40549999475479126,\n",
       "  0.46000000834465027,\n",
       "  0.5404999852180481,\n",
       "  0.33125001192092896,\n",
       "  0.734000027179718],\n",
       " 'top5_acc_per_type': [0.6122499704360962,\n",
       "  0.6582499742507935,\n",
       "  0.7310000061988831,\n",
       "  0.5212500095367432,\n",
       "  0.8812500238418579],\n",
       " 'error_rate_per_type': [0.5945000052452087,\n",
       "  0.5399999916553497,\n",
       "  0.4595000147819519,\n",
       "  0.668749988079071,\n",
       "  0.265999972820282],\n",
       " 'ece': 0.00032730889059603215,\n",
       " 'entropy': 2.319790731048584}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_module.test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
