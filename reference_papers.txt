-> first


-> second


-> third




EXPERIMENTS:
cifar_types = ["brightness", "defocus_blur", "zoom_blur", "motion_blur", "fog", "frost", "snow", "shot_noise", "gaussian_noise", "jpeg_compression"]
tinyIN_types = ["motion_blur", "shot_noise", "jpeg_compression", "fog"]


-> Inference experiments:

-> Regularization experiments
    - Dropout
    - Erasing aug
    - Stoch. Depth
    - Repeated Aug
    - label smoothing

PLAN:
-> Update train-test-loss functions for finetuning deit3
-> finetune deit3 on corrupted
    - Use data augmentations
    - correct hyperparams
-> distill deit3 on deit on corrupted data
-> distill deit3 on Cdeit on corrupted data
-- Note train-test metrics for all

----------------------------------------------------------------------------------------------------------------
                                        DEIT3 ex1
-> lr: 
    - 1e-5 does not work with or without model frozen, no learning of new head
    - 5e-4 breaks down model - but with model frozen, good untill 10 epochs
    


---------------------------------------------------------------------------------------------------------------------

PAPERS:
- AN IMAGE IS WORTH 16X16 WORDS: TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE

- Vision Transformer for Small-Size Datasets

- Benchmarking Neural Network Robustness to Common Corruptions and Perturbations

- Attention is all you need 

- Powerful Design of Small Vision Transformer on CIFAR10

- Training data-efficient image transformers & distillation through attention

- Improving Robustness of Vision Transformers by Reducing Sensitivity to Patch Corruptions

- A Survey on the Robustness of Computer Vision Models against Common Corruptions

- Parameter-Efficient Fine-Tuning for Pre-Trained Vision Models: A Survey and Benchmark

- Towards Robust Vision Transformer


