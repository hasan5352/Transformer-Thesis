EXPERIMENTS:
-> Inference experiments:

-> Regularization experiments
    - Dropout
    - Erasing
    - Stoch. Depth
    - Repeated Aug
    - label smoothing

-> Teacher Experiments:
    - train all teachers and collect for each epoch: acc@1, acc@5, loss, 
    
TEACHERS:
- Deit-Small
- ConvNet tiny

PLAN:
-> Update train-test-loss functions for finetuning deit3
-> finetune deit3 on corrupted
    - Use data augmentations
    - correct hyperparams
-> distill deit3 on deit on corrupted data
-> distill deit3 on Cdeit on corrupted data
-- Note train-test metrics for all


PAPERS:
- AN IMAGE IS WORTH 16X16 WORDS: TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE

- Vision Transformer for Small-Size Datasets

- Benchmarking Neural Network Robustness to Common Corruptions and Perturbations

- Attention is all you need 

- Powerful Design of Small Vision Transformer on CIFAR10

- Training data-efficient image transformers & distillation through attention

- Improving Robustness of Vision Transformers by Reducing Sensitivity to Patch Corruptions

- A Survey on the Robustness of Computer Vision Models against Common Corruptions


