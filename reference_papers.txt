EXPERIMENTS:
-> Inference experiments:

-> Regularization experiments
    - Dropout
    - Erasing
    - Stoch. Depth
    - Repeated Aug
    - label smoothing

-> Teacher Experiments:
    - train all teachers and collect for each epoch: acc@1, acc@5, loss, 
    
TEACHERS:
- RegNety800mf  --> 6.4M --> 78%
- EfficientNet-B1  --> 7.8M -- > 80%

- If Time left: ResNet18  --> 11.7M --> 70%


PAPERS:
- AN IMAGE IS WORTH 16X16 WORDS: TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE

- Vision Transformer for Small-Size Datasets

- Benchmarking Neural Network Robustness to Common Corruptions and Perturbations

- Attention is all you need 

- Powerful Design of Small Vision Transformer on CIFAR10

- Training data-efficient image transformers & distillation through attention

- Improving Robustness of Vision Transformers by Reducing Sensitivity to Patch Corruptions

- A Survey on the Robustness of Computer Vision Models against Common Corruptions


