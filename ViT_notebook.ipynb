{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4f574bd",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "- [Download corrupted Cifar10 .tar](https://zenodo.org/records/2535967) and extract it into a folder.\n",
    "\n",
    "- Cifar10 is downloaded using torch.datasets\n",
    "\n",
    "- [Download corrupted Tiny-ImageNet](https://zenodo.org/records/2536630) and extract it into a folder.\n",
    "\n",
    "- [Download Tiny-ImageNet](https://www.kaggle.com/datasets/akash2sharma/tiny-imagenet) and extract it into a folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390b7c4a",
   "metadata": {},
   "source": [
    "# Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c1ea522",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hp\\anaconda3\\envs\\deepLearning\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\Hp\\anaconda3\\envs\\deepLearning\\lib\\site-packages\\timm\\models\\layers\\__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import timm\n",
    "\n",
    "from my_transformers import CorruptDistillVisionTransformer\n",
    "from utils import load_experimental_TinyImageNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2ed7d8",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "061ec91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupt_types = [\"motion_blur\", \"shot_noise\", \"jpeg_compression\", \"fog\"]\n",
    "\n",
    "# corrupt_path = r\"C:\\Users\\Hp\\Desktop\\Coding\\Transformer-Thesis\\Tiny-ImageNet-C\\Tiny-ImageNet-C\"\n",
    "# normal_path = r\"C:\\Users\\Hp\\Desktop\\Coding\\Transformer-Thesis\\Tiny-ImageNet-Normal\"\n",
    "# train_data, test_data = load_experimental_TinyImageNet(normal_path, corrupt_path, corrupt_types, num_train_imgs=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b68f313",
   "metadata": {},
   "source": [
    "# Visualisation TinyImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6f8790",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_to_img(tensor):\n",
    "    mean = torch.tensor([0.4802, 0.4481, 0.3975])\n",
    "    std = torch.tensor([0.2302, 0.2265, 0.2262])\n",
    "    \n",
    "    # denormalize\n",
    "    img = tensor.clone()\n",
    "    img = img * std[:, None, None] + mean[:, None, None]\n",
    "    img = torch.clamp(img, 0, 1)\n",
    "    \n",
    "    # convert to PIL image\n",
    "    to_pil = T.ToPILImage()\n",
    "    return to_pil(img)\n",
    "\n",
    "# plot\n",
    "imgs_to_display = [random.randint(0, len(train_data[0])-1) for i in range(9)]\n",
    "fig, axes = plt.subplots(3, 3, figsize=(4, 4))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(9):\n",
    "    img, label = train_data[0][imgs_to_display[i]], train_data[2][imgs_to_display[i]].item()\n",
    "    img = tensor_to_img(img)\n",
    "    if label == len(corrupt_types):\n",
    "        axes[i].set_title(f\"normal\", fontsize=8)\n",
    "    else:\n",
    "        axes[i].set_title(corrupt_types[label], fontsize=8)\n",
    "    axes[i].imshow(img)\n",
    "    axes[i].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8c65ee",
   "metadata": {},
   "source": [
    "# Model config for TinyImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63e646c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting seed \n",
    "torch.cuda.manual_seed(22)\n",
    "random.seed(22)\n",
    "torch.manual_seed(22)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "corrupt_types = [\"motion_blur\", \"shot_noise\", \"jpeg_compression\", \"fog\"]\n",
    "\n",
    "# Hyper-parameters\n",
    "PATCH_SIZE = 8\n",
    "IMG_SIZE = 64\n",
    "EMBED_DIM = 192\n",
    "NUM_HEADS = 3\n",
    "NUM_IMG_TYPES = len(corrupt_types)+1\n",
    "NUM_ENCODERS = 12\n",
    "NUM_CLASSES = 200\n",
    "DROPOUT = 0\n",
    "DROP_PATH = 0.1\n",
    "ERASE_PROB = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d2aaa24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21751496\n",
      "Linear(in_features=384, out_features=200, bias=True)\n"
     ]
    }
   ],
   "source": [
    "# train_data = torch.load(\"train_data.pt\", weights_only=True)\n",
    "# test_data = torch.load(\"test_data.pt\", weights_only=True)\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "# train_loader = DataLoader(dataset=TensorDataset(*torch.load(\"train_data.pt\", weights_only=True)), \n",
    "#                                   batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=TensorDataset(*torch.load(\"test_data.pt\", weights_only=True)), \n",
    "                                 batch_size=BATCH_SIZE, shuffle=True)\n",
    "itr = iter(test_loader)\n",
    "train_batch = [next(itr)]\n",
    "test_batch = [next(itr)]\n",
    "\n",
    "# deit3_small_patch16_224.fb_in22k_ft_in1k -- 22M\n",
    "# convnext_tiny.fb_in22k_ft_in1k -- 28M\n",
    "deit3_small = timm.create_model('deit3_small_patch16_224.fb_in22k_ft_in1k', pretrained=True).cuda()\n",
    "# teacher_model = timm.create_model('vit_small_patch16_224.augreg_in21k_ft_in1k', pretrained=True).cuda()\n",
    "deit3_small.head = nn.Linear(in_features=384, out_features=NUM_CLASSES, bias=True).cuda()\n",
    "num_params = sum(p.numel() for p in deit3_small.parameters())\n",
    "print(num_params)\n",
    "print(deit3_small.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41f4a758",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_test_module import compute_ece\n",
    "import json\n",
    "\n",
    "class TrainTestBaseline:\n",
    "    def __init__(self, model, train_batches, test_batches, num_img_types, device):\n",
    "        self.model = model.to(device)\n",
    "        self.train_batches = train_batches\n",
    "        self.test_batches = test_batches\n",
    "        self.num_img_types = num_img_types\n",
    "        self.device = device\n",
    "\n",
    "        self.all_test_metrics, self.all_train_metrics = [], []\n",
    "\n",
    "    def test(self, print_metrics=False):\n",
    "        top1_correct_preds, top5_correct_preds = 0, 0\n",
    "        total_samples, total_ece, total_entropy = 0, 0, 0\n",
    "\n",
    "        total_per_type = torch.zeros(self.num_img_types, device=self.device)\n",
    "        top1_correct_per_type = torch.zeros(self.num_img_types, device=self.device)\n",
    "        top5_correct_per_type = torch.zeros(self.num_img_types, device=self.device)\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for x_batch, y_batch, c_batch in self.test_batches:\n",
    "                x_batch, y_batch, c_batch = x_batch.to(self.device), y_batch.to(self.device), c_batch.to(self.device)\n",
    "                x_batch = F.interpolate(x_batch, size=(224, 224), mode='bilinear', align_corners=False)\n",
    "                preds = self.model(x_batch)\n",
    "                del x_batch \n",
    "                \n",
    "                total_samples += y_batch.size(0)\n",
    "                # top-1 acc\n",
    "                top1_right = (torch.argmax(preds, dim=1) == y_batch)\n",
    "                top1_correct_preds += top1_right.sum().item()\n",
    "                # top-5 acc\n",
    "                top5_right = torch.topk(preds, 5, dim=1).indices.eq(y_batch.unsqueeze(1)).any(dim=1)\n",
    "                top5_correct_preds += top5_right.sum().item()\n",
    "                # ECE loss\n",
    "                total_ece += compute_ece(preds, y_batch, self.device)\n",
    "                # Per-type acc\n",
    "                for t in range(self.num_img_types):\n",
    "                    mask = (c_batch == t)\n",
    "                    total_per_type[t] += mask.sum()\n",
    "                    top1_correct_per_type[t] += top1_right[mask].sum()\n",
    "                    top5_correct_per_type[t] += top5_right[mask].sum()\n",
    "                # entropy\n",
    "                total_entropy += -torch.sum(torch.softmax(preds, dim=1) * torch.log_softmax(preds, dim=1), dim=1).sum().item()\n",
    "                del y_batch, c_batch\n",
    "                \n",
    "        top1_acc_per_type = (top1_correct_per_type / total_per_type).tolist()\n",
    "        test_metrics = {\n",
    "            \"top1_acc\" : top1_correct_preds / total_samples, \n",
    "            \"top5_acc\" : top5_correct_preds / total_samples, \n",
    "            \"top1_acc_per_type\" : top1_acc_per_type,\n",
    "            \"top5_acc_per_type\" :(top5_correct_per_type / total_per_type).tolist(), \n",
    "            \"error_rate_per_type\" : [1 - acc for acc in top1_acc_per_type],\n",
    "            \"ece\" : total_ece / total_samples,\n",
    "            \"entropy\" : total_entropy / total_samples\n",
    "        }\n",
    "        if print_metrics : print(f\"Test-Accuracy:{test_metrics['top1_acc']:.2f}\")\n",
    "        return test_metrics\n",
    "    \n",
    "    def train(self, optimizer, scheduler, save_path, num_epochs=1, label_smoothing=0.1, print_metrics=False):\n",
    "        best_acc, epochs_no_improve, min_delta, patience = 0, 0, 0.003, 4\n",
    "        self.model.train()\n",
    "        for epoch in range(1, num_epochs+1):\n",
    "            print(f\"------- Epoch {epoch} -------\")\n",
    "            total_samples, top1_correct_preds, loss_total = 0, 0, 0\n",
    "\n",
    "            for x_batch, y_batch, _ in self.test_batches:\n",
    "                x_batch, y_batch = x_batch.to(self.device), y_batch.to(self.device)\n",
    "                x_batch = F.interpolate(x_batch, size=(224, 224), mode='bilinear', align_corners=False)\n",
    "                preds = self.model(x_batch)\n",
    "\n",
    "                del x_batch                 # free memory\n",
    "                total_samples += y_batch.size(0)\n",
    "                # top-1 acc\n",
    "                top1_correct_preds += (torch.argmax(preds, dim=1) == y_batch).sum().item()\n",
    "                #loss\n",
    "                loss = F.cross_entropy(preds, y_batch, label_smoothing=label_smoothing)\n",
    "                # backprop\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                scheduler.step() \n",
    "\n",
    "                loss_total += loss.item() * y_batch.size(0)\n",
    "                del y_batch, preds, loss            # free memory\n",
    "\n",
    "            test_metrics = self.test()\n",
    "            train_metrics = {\n",
    "                \"loss_total\": loss_total/total_samples,\n",
    "                \"top1_acc\" : top1_correct_preds / total_samples\n",
    "                }\n",
    "            current_acc = test_metrics['top1_acc']\n",
    "            if print_metrics : \n",
    "                print(f\"train-loss: {train_metrics['loss_total']:.2f} -- train-acc: {train_metrics['top1_acc']:.2f} -- \"\n",
    "                      f\"train-acc: {current_acc:.2f}\"\n",
    "                      )\n",
    "            self.all_train_metrics.append(train_metrics)\n",
    "            self.all_test_metrics.append(test_metrics)\n",
    "            # early stopping\n",
    "            if current_acc - best_acc > min_delta:\n",
    "                best_acc = current_acc\n",
    "                epochs_no_improve = 0\n",
    "            else:\n",
    "                epochs_no_improve += 1\n",
    "\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch} â€” no improvement in {patience} epochs.\")\n",
    "                break\n",
    "        \n",
    "        # save trained model and metrics\n",
    "        if save_path:\n",
    "            torch.save(self.model.state_dict(), f\"{save_path}.pth\")\n",
    "            print(f\"Model saved to {save_path}\")\n",
    "            \n",
    "            with open(f\"{save_path}_train_metrics.json\", \"w\") as f1:\n",
    "                json.dump(self.all_train_metrics, f1, indent=4)\n",
    "            with open(f\"{save_path}_test_metrics.json\", \"w\") as f2:\n",
    "                json.dump(self.all_test_metrics, f2, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b3df68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === LR Scheduler ===\n",
    "NUM_EPOCHS = 50\n",
    "WARMUP_EPOCHS = 3\n",
    "total_steps = NUM_EPOCHS * len(train_loader)\n",
    "warmup_steps = WARMUP_EPOCHS * len(train_loader)\n",
    "\n",
    "optimizer = optim.AdamW(deit3_small.parameters(), lr=5e-5, weight_decay=0.05)\n",
    "warmup_scheduler = optim.lr_scheduler.LinearLR(optimizer, start_factor=1e-5, total_iters=warmup_steps)\n",
    "lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS-WARMUP_EPOCHS)\n",
    "scheduler = optim.lr_scheduler.SequentialLR(\n",
    "    optimizer, schedulers=[warmup_scheduler, lr_scheduler], milestones=[warmup_steps]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8541180",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_test_module import LossCalculator\n",
    "class TrainTestStudentDeiT:\n",
    "    def __init__(self, model, train_batches, test_batches, head_strategy, num_img_types,\n",
    "                 device, save_path:str, teacher_model=None\n",
    "                 ):\n",
    "        assert head_strategy > 0 and head_strategy <= 3\n",
    "        self.model = model.to(device)\n",
    "        if teacher_model: self.teacher_model = teacher_model.to(device)\n",
    "        self.train_batches = train_batches\n",
    "        self.test_batches = test_batches\n",
    "        self.head_strategy = head_strategy\n",
    "        self.num_img_types = num_img_types\n",
    "        self.save_path = save_path\n",
    "        self.device = device\n",
    "\n",
    "        self.all_test_metrics, self.all_train_metrics = [], []\n",
    "    \n",
    "    # testing function\n",
    "    def test(self, print_metrics=False):\n",
    "        top1_correct_preds, top5_correct_preds = 0, 0\n",
    "        top1_correct_corruptions, total_samples, total_ece, total_entropy = 0, 0, 0, 0\n",
    "\n",
    "        total_per_type = torch.zeros(self.num_img_types, device=self.device)\n",
    "        top1_correct_per_type = torch.zeros(self.num_img_types, device=self.device)\n",
    "        top5_correct_per_type = torch.zeros(self.num_img_types, device=self.device)\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for x_batch, y_batch, c_batch in self.test_batches:\n",
    "                x_batch, y_batch, c_batch = x_batch.to(self.device), y_batch.to(self.device), c_batch.to(self.device)\n",
    "                tokens = self.model(x_batch)\n",
    "                del x_batch\n",
    "                \n",
    "                if len(tokens) == 3 and self.head_strategy != 1:\n",
    "                    preds = (tokens[0] + tokens[1] + self.model.output_head.corrupt_connection(tokens[2])) / 3\n",
    "                else:\n",
    "                    preds = (tokens[0] + tokens[1]) / 2\n",
    "                    print(tokens[0].shape, tokens[1].shape, preds.shape)\n",
    "                \n",
    "                total_samples += y_batch.size(0)\n",
    "                # top-1 acc\n",
    "                top1_right = (torch.argmax(preds, dim=1) == y_batch)\n",
    "                top1_correct_preds += top1_right.sum().item()\n",
    "                # top-5 acc\n",
    "                top5_right = torch.topk(preds, 5, dim=1).indices.eq(y_batch.unsqueeze(1)).any(dim=1)\n",
    "                top5_correct_preds += top5_right.sum().item()\n",
    "                # ECE loss\n",
    "                total_ece += compute_ece(preds, y_batch, self.device)\n",
    "                # Per-type acc\n",
    "                for t in range(self.num_img_types):\n",
    "                    mask = (c_batch == t)\n",
    "                    total_per_type[t] += mask.sum()\n",
    "                    top1_correct_per_type[t] += top1_right[mask].sum()\n",
    "                    top5_correct_per_type[t] += top5_right[mask].sum()\n",
    "                # entropy\n",
    "                total_entropy += -torch.sum(torch.softmax(preds, dim=1) * torch.log_softmax(preds, dim=1), dim=1).sum().item()\n",
    "                # top-1 corruption classification acc\n",
    "                if len(tokens) == 3 : top1_correct_corruptions += (torch.argmax(tokens[2], dim=1) == c_batch).sum().item()              \n",
    "                del y_batch, c_batch, preds\n",
    "\n",
    "        top1_acc_per_type = (top1_correct_per_type / total_per_type).tolist()\n",
    "        test_metrics = {\n",
    "            \"top1_acc\" : top1_correct_preds / total_samples, \n",
    "            \"top5_acc\" : top5_correct_preds / total_samples, \n",
    "            \"top1_acc_per_type\" : top1_acc_per_type,\n",
    "            \"top5_acc_per_type\" :(top5_correct_per_type / total_per_type).tolist(), \n",
    "            \"error_rate_per_type\" : [1 - acc for acc in top1_acc_per_type],\n",
    "            \"ece\" : total_ece / total_samples,\n",
    "            \"entropy\" : total_entropy / total_samples\n",
    "        }\n",
    "        if top1_correct_corruptions : test_metrics[\"top1_corrupt_acc\"] = top1_correct_corruptions / total_samples\n",
    "        if print_metrics : print(f\"Test-Accuracy:{test_metrics['top1_acc']:.2f}\")\n",
    "        return test_metrics\n",
    "\n",
    "    # ------------ training function ------------\n",
    "    def train_cdeit_model(self, optimizer, num_epochs=1):\n",
    "        self.model.train()\n",
    "        for epoch in range(1, num_epochs+1):\n",
    "            loss_total, loss_corrupt, loss_distill, loss_cls = 0, 0, 0, 0\n",
    "            total_samples, sim_cls_distill, sim_cls_corr = 0, 0, 0\n",
    "\n",
    "            print(f\"------- Epoch {epoch} -------\")\n",
    "            for x_batch, y_batch, c_batch in self.train_batches:\n",
    "                x_batch, y_batch, c_batch = x_batch.to(self.device), y_batch.to(self.device), c_batch.to(self.device)\n",
    "                tokens = self.model(x_batch)\n",
    "                \n",
    "                loss_calculater = LossCalculator(self.teacher_model)\n",
    "                L_corrupt = None\n",
    "                if len(tokens) == 3:\n",
    "                    L_total, L_cls, L_distill, L_corrupt = loss_calculater((third_batch, y_batch, c_batch), tokens)\n",
    "                else:\n",
    "                    L_total, L_cls, L_distill = loss_calculater((third_batch, y_batch), tokens)\n",
    "\n",
    "                # backprop\n",
    "                optimizer.zero_grad()\n",
    "                L_total.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                total_samples += y_batch.size(0)\n",
    "                # losses\n",
    "                loss_total += L_total.item() * y_batch.size(0)\n",
    "                loss_cls += L_cls.item() * y_batch.size(0)\n",
    "                loss_distill += L_distill.item() * y_batch.size(0)\n",
    "                if L_corrupt : loss_corrupt += L_corrupt.item() * y_batch.size(0)\n",
    "\n",
    "                # cosine similarity\n",
    "                sim_cls_distill += self.model.sim_cls_distill_end\n",
    "                sim_cls_corr += self.model.sim_cls_corr_end\n",
    "\n",
    "            train_metrics = {\n",
    "                \"loss_total\": loss_total/total_samples,\n",
    "                \"loss_cls\": loss_cls/total_samples,\n",
    "                \"loss_distill\": loss_distill/total_samples,\n",
    "                \"sim_cls_distill\" : sim_cls_distill/total_samples,\n",
    "                \"sim_cls_corr\" : sim_cls_corr/total_samples\n",
    "            }\n",
    "            if loss_corrupt : train_metrics[\"loss_corrupt\"] = loss_corrupt/total_samples\n",
    "            if self.print_metrics : print(f\"Train-Loss: {train_metrics['loss_total']:.3f}\")\n",
    "            test_metrics = self.test_cdeit_model()\n",
    "            self.all_train_metrics.append(train_metrics)\n",
    "            self.all_test_metrics.append(test_metrics)\n",
    "        \n",
    "        # save trained model\n",
    "        torch.save(self.model.state_dict(), self.save_path)\n",
    "        print(f\"\\nModel saved to {self.save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4aa2031d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200]) torch.Size([200]) torch.Size([200])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 9\u001b[0m\n\u001b[0;32m      3\u001b[0m deit_small \u001b[38;5;241m=\u001b[39m DistillVisionTransformer(\n\u001b[0;32m      4\u001b[0m     EMBED_DIM, IMG_SIZE, PATCH_SIZE, NUM_CLASSES, attention_heads\u001b[38;5;241m=\u001b[39mNUM_HEADS,\n\u001b[0;32m      5\u001b[0m     num_encoders\u001b[38;5;241m=\u001b[39mNUM_ENCODERS, dropout\u001b[38;5;241m=\u001b[39mDROPOUT, drop_path\u001b[38;5;241m=\u001b[39mDROP_PATH, erase_prob\u001b[38;5;241m=\u001b[39mERASE_PROB \n\u001b[0;32m      6\u001b[0m     )\n\u001b[0;32m      8\u001b[0m train_student_module \u001b[38;5;241m=\u001b[39m TrainTestStudentDeiT(deit_small, train_batch, test_batch, \u001b[38;5;241m1\u001b[39m, NUM_IMG_TYPES, device, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m \u001b[43mtrain_student_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[11], line 42\u001b[0m, in \u001b[0;36mTrainTestStudentDeiT.test\u001b[1;34m(self, print_metrics)\u001b[0m\n\u001b[0;32m     40\u001b[0m total_samples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m y_batch\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# top-1 acc\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m top1_right \u001b[38;5;241m=\u001b[39m (\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m==\u001b[39m y_batch)\n\u001b[0;32m     43\u001b[0m top1_correct_preds \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m top1_right\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# top-5 acc\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "from my_transformers import DistillVisionTransformer\n",
    "\n",
    "deit_small = DistillVisionTransformer(\n",
    "    EMBED_DIM, IMG_SIZE, PATCH_SIZE, NUM_CLASSES, attention_heads=NUM_HEADS,\n",
    "    num_encoders=NUM_ENCODERS, dropout=DROPOUT, drop_path=DROP_PATH, erase_prob=ERASE_PROB \n",
    "    )\n",
    "\n",
    "train_student_module = TrainTestStudentDeiT(deit_small, train_batch, test_batch, 1, NUM_IMG_TYPES, device, \"\")\n",
    "train_student_module.test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
