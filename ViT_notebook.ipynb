{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4f574bd",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "- [Download corrupted Cifar10 .tar](https://zenodo.org/records/2535967) and extract it into a folder.\n",
    "\n",
    "- Cifar10 is downloaded using torch.datasets\n",
    "\n",
    "- [Download corrupted Tiny-ImageNet](https://zenodo.org/records/2536630) and extract it into a folder.\n",
    "\n",
    "- [Download Tiny-ImageNet](https://www.kaggle.com/datasets/akash2sharma/tiny-imagenet) and extract it into a folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390b7c4a",
   "metadata": {},
   "source": [
    "# Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c1ea522",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hp\\anaconda3\\envs\\deepLearning\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\Hp\\anaconda3\\envs\\deepLearning\\lib\\site-packages\\timm\\models\\layers\\__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import timm\n",
    "\n",
    "from my_transformers import CorruptDistillVisionTransformer\n",
    "from utils import load_experimental_TinyImageNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2ed7d8",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "061ec91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupt_types = [\"motion_blur\", \"shot_noise\", \"jpeg_compression\", \"fog\"]\n",
    "\n",
    "# corrupt_path = r\"C:\\Users\\Hp\\Desktop\\Coding\\Transformer-Thesis\\Tiny-ImageNet-C\\Tiny-ImageNet-C\"\n",
    "# normal_path = r\"C:\\Users\\Hp\\Desktop\\Coding\\Transformer-Thesis\\Tiny-ImageNet-Normal\"\n",
    "# train_data, test_data = load_experimental_TinyImageNet(normal_path, corrupt_path, corrupt_types, num_train_imgs=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b68f313",
   "metadata": {},
   "source": [
    "# Visualisation TinyImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6f8790",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_to_img(tensor):\n",
    "    mean = torch.tensor([0.4802, 0.4481, 0.3975])\n",
    "    std = torch.tensor([0.2302, 0.2265, 0.2262])\n",
    "    \n",
    "    # denormalize\n",
    "    img = tensor.clone()\n",
    "    img = img * std[:, None, None] + mean[:, None, None]\n",
    "    img = torch.clamp(img, 0, 1)\n",
    "    \n",
    "    # convert to PIL image\n",
    "    to_pil = T.ToPILImage()\n",
    "    return to_pil(img)\n",
    "\n",
    "# plot\n",
    "imgs_to_display = [random.randint(0, len(train_data[0])-1) for i in range(9)]\n",
    "fig, axes = plt.subplots(3, 3, figsize=(4, 4))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(9):\n",
    "    img, label = train_data[0][imgs_to_display[i]], train_data[2][imgs_to_display[i]].item()\n",
    "    img = tensor_to_img(img)\n",
    "    if label == len(corrupt_types):\n",
    "        axes[i].set_title(f\"normal\", fontsize=8)\n",
    "    else:\n",
    "        axes[i].set_title(corrupt_types[label], fontsize=8)\n",
    "    axes[i].imshow(img)\n",
    "    axes[i].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8c65ee",
   "metadata": {},
   "source": [
    "# Model config for TinyImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63e646c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting seed \n",
    "torch.cuda.manual_seed(22)\n",
    "random.seed(22)\n",
    "torch.manual_seed(22)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "corrupt_types = [\"motion_blur\", \"shot_noise\", \"jpeg_compression\", \"fog\"]\n",
    "\n",
    "# Hyper-parameters\n",
    "PATCH_SIZE = 8\n",
    "IMG_SIZE = 64\n",
    "EMBED_DIM = 192\n",
    "NUM_HEADS = 3\n",
    "NUM_IMG_TYPES = len(corrupt_types)+1\n",
    "NUM_ENCODERS = 12\n",
    "NUM_CLASSES = 200\n",
    "DROPOUT = 0\n",
    "DROP_PATH = 0.1\n",
    "ERASE_PROB = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d2aaa24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21751496\n",
      "Linear(in_features=384, out_features=200, bias=True)\n"
     ]
    }
   ],
   "source": [
    "# train_data = torch.load(\"train_data.pt\", weights_only=True)\n",
    "# test_data = torch.load(\"test_data.pt\", weights_only=True)\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "# train_loader = DataLoader(dataset=TensorDataset(*torch.load(\"train_data.pt\", weights_only=True)), \n",
    "#                                   batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=TensorDataset(*torch.load(\"test_data.pt\", weights_only=True)), \n",
    "                                 batch_size=BATCH_SIZE, shuffle=True)\n",
    "itr = iter(test_loader)\n",
    "train_batch = [next(itr)]\n",
    "test_batch = [next(itr)]\n",
    "\n",
    "# deit3_small_patch16_224.fb_in22k_ft_in1k -- 22M\n",
    "# convnext_tiny.fb_in22k_ft_in1k -- 28M\n",
    "teacher_model = timm.create_model('deit3_small_patch16_224.fb_in22k_ft_in1k', pretrained=True).cuda()\n",
    "# teacher_model = timm.create_model('vit_small_patch16_224.augreg_in21k_ft_in1k', pretrained=True).cuda()\n",
    "teacher_model.head = nn.Linear(in_features=384, out_features=NUM_CLASSES, bias=True).cuda()\n",
    "num_params = sum(p.numel() for p in teacher_model.parameters())\n",
    "print(num_params)\n",
    "print(teacher_model.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f4a758",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_test_module import compute_ece\n",
    "import json\n",
    "\n",
    "class TrainTest_TeacherFt:\n",
    "    def __init__(self, model, train_batches, test_batches, num_img_types, device):\n",
    "        self.model = model.to(device)\n",
    "        self.train_batches = train_batches\n",
    "        self.test_batches = test_batches\n",
    "        self.num_img_types = num_img_types\n",
    "        self.device = device\n",
    "\n",
    "        self.all_test_metrics, self.all_train_metrics = [], []\n",
    "\n",
    "    def test(self, print_metrics=False):\n",
    "        top1_correct_preds, top5_correct_preds = 0, 0\n",
    "        total_samples, total_ece, total_entropy = 0, 0, 0\n",
    "\n",
    "        total_per_type = torch.zeros(self.num_img_types, device=self.device)\n",
    "        top1_correct_per_type = torch.zeros(self.num_img_types, device=self.device)\n",
    "        top5_correct_per_type = torch.zeros(self.num_img_types, device=self.device)\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for x_batch, y_batch, c_batch in self.test_batches:\n",
    "                x_batch, y_batch, c_batch = x_batch.to(self.device), y_batch.to(self.device), c_batch.to(self.device)\n",
    "                x_batch = F.interpolate(x_batch, size=(224, 224), mode='bilinear', align_corners=False)\n",
    "                preds = self.model(x_batch)\n",
    "                del x_batch \n",
    "                \n",
    "                total_samples += y_batch.size(0)\n",
    "                # top-1 acc\n",
    "                top1_right = (torch.argmax(preds, dim=1) == y_batch)\n",
    "                top1_correct_preds += top1_right.sum().item()\n",
    "                # top-5 acc\n",
    "                top5_right = torch.topk(preds, 5, dim=1).indices.eq(y_batch.unsqueeze(1)).any(dim=1)\n",
    "                top5_correct_preds += top5_right.sum().item()\n",
    "                # ECE loss\n",
    "                total_ece += compute_ece(preds, y_batch, self.device)\n",
    "                # Per-type acc\n",
    "                for t in range(self.num_img_types):\n",
    "                    mask = (c_batch == t)\n",
    "                    total_per_type[t] += mask.sum()\n",
    "                    top1_correct_per_type[t] += top1_right[mask].sum()\n",
    "                    top5_correct_per_type[t] += top5_right[mask].sum()\n",
    "                # entropy\n",
    "                total_entropy += -torch.sum(torch.softmax(preds, dim=1) * torch.log_softmax(preds, dim=1), dim=1).sum().item()\n",
    "                del y_batch, c_batch\n",
    "                \n",
    "        top1_acc_per_type = (top1_correct_per_type / total_per_type).tolist()\n",
    "        test_metrics = {\n",
    "            \"top1_acc\" : top1_correct_preds / total_samples, \n",
    "            \"top5_acc\" : top5_correct_preds / total_samples, \n",
    "            \"top1_acc_per_type\" : top1_acc_per_type,\n",
    "            \"top5_acc_per_type\" :(top5_correct_per_type / total_per_type).tolist(), \n",
    "            \"error_rate_per_type\" : [1 - acc for acc in top1_acc_per_type],\n",
    "            \"ece\" : total_ece / total_samples,\n",
    "            \"entropy\" : total_entropy / total_samples\n",
    "        }\n",
    "        if print_metrics : print(f\"Test-Accuracy:{test_metrics['top1_acc']:.2f}\")\n",
    "        return test_metrics\n",
    "    \n",
    "    def train(self, optimizer, save_path, num_epochs=1, print_metrics=False):\n",
    "        total_samples, top1_correct_preds, loss_total = 0, 0, 0\n",
    "        self.model.train()\n",
    "        for epoch in range(1, num_epochs+1):\n",
    "            print(f\"------- Epoch {epoch} -------\")\n",
    "            for x_batch, y_batch, _ in self.test_batches:\n",
    "                x_batch, y_batch = x_batch.to(self.device), y_batch.to(self.device)\n",
    "                x_batch = F.interpolate(x_batch, size=(224, 224), mode='bilinear', align_corners=False)\n",
    "                preds = self.model(x_batch)\n",
    "                del x_batch\n",
    "                total_samples += y_batch.size(0)\n",
    "                # top-1 acc\n",
    "                top1_right = (torch.argmax(preds, dim=1) == y_batch)\n",
    "                top1_correct_preds += top1_right.sum().item()\n",
    "                #loss\n",
    "                loss = F.cross_entropy(preds, y_batch)\n",
    "                # backprop\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                loss_total += loss.item() * y_batch.size(0)\n",
    "                del y_batch, \n",
    "\n",
    "            test_metrics = self.test()\n",
    "            train_metrics = {\n",
    "                \"loss_total\": loss_total/total_samples,\n",
    "                \"top1_acc\" : top1_correct_preds / total_samples\n",
    "                }\n",
    "            if print_metrics : \n",
    "                print(f\"train-loss: {train_metrics['loss_total']:.2f} -- train-acc: {train_metrics['top1_acc']:.2f} -- \"\n",
    "                      f\"train-acc: {test_metrics['top1_acc']:.2f}\"\n",
    "                      )\n",
    "            self.all_train_metrics.append(train_metrics)\n",
    "            self.all_test_metrics.append(test_metrics)\n",
    "        \n",
    "        # save trained model\n",
    "        if save_path:\n",
    "            torch.save(self.model.state_dict(), f\"{save_path}.pth\")\n",
    "            print(f\"Model saved to {save_path}\")\n",
    "            \n",
    "            with open(f\"{save_path}_train_metrics.json\", \"w\") as f1:\n",
    "                json.dump(self.all_train_metrics, f1, indent=4)\n",
    "            with open(f\"{save_path}_test_metrics.json\", \"w\") as f2:\n",
    "                json.dump(self.all_test_metrics, f2, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c109094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Epoch 1 -------\n",
      "Model saved to lulu\n"
     ]
    }
   ],
   "source": [
    "train_test_teacher = TrainTest_TeacherFt(teacher_model, train_batch, test_batch, NUM_IMG_TYPES, device)\n",
    "optimizer = optim.AdamW(teacher_model.parameters(), lr=1e-4, weight_decay=0.05)\n",
    "train_test_teacher.train(optimizer, \"lulu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e016d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'top1_acc': 0.3671875,\n",
       "  'top5_acc': 0.5859375,\n",
       "  'top1_acc_per_type': [0.29032257199287415,\n",
       "   0.5,\n",
       "   0.3448275923728943,\n",
       "   0.4000000059604645,\n",
       "   0.30000001192092896],\n",
       "  'top5_acc_per_type': [0.4516128897666931,\n",
       "   0.75,\n",
       "   0.5862069129943848,\n",
       "   0.6499999761581421,\n",
       "   0.5],\n",
       "  'error_rate_per_type': [0.7096774280071259,\n",
       "   0.5,\n",
       "   0.6551724076271057,\n",
       "   0.5999999940395355,\n",
       "   0.699999988079071],\n",
       "  'ece': 0.0017773996805772185,\n",
       "  'entropy': 4.249937057495117}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_teacher.all_test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8541180",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_test_module import LossCalculator\n",
    "class TrainTestdeit:\n",
    "    def __init__(self, model, teacher_model, train_batches, test_batches, head_strategy, num_img_types,\n",
    "                 device, save_path:str, print_metrics=False, n_bins=15\n",
    "                 ):\n",
    "        assert head_strategy > 0 and head_strategy <= 3\n",
    "        self.model = model.to(device)\n",
    "        self.teacher_model = teacher_model.to(device)\n",
    "        self.train_batches = train_batches\n",
    "        self.test_batches = test_batches\n",
    "        self.head_strategy = head_strategy\n",
    "        self.num_img_types = num_img_types\n",
    "        self.save_path = save_path\n",
    "\n",
    "        self.device = device\n",
    "        self.print_metrics = print_metrics\n",
    "        self.n_bins = n_bins\n",
    "\n",
    "        self.all_test_metrics, self.all_train_metrics = [], []\n",
    "    \n",
    "    # testing function\n",
    "    def test_cdeit_model(self):\n",
    "        top1_correct_preds, top5_correct_preds = 0, 0\n",
    "        top1_correct_corrs, total_samples, total_ece, total_entropy = 0, 0, 0, 0\n",
    "\n",
    "        total_per_type = torch.zeros(self.num_img_types, device=self.device)\n",
    "        top1_correct_per_type = torch.zeros(self.num_img_types, device=self.device)\n",
    "        top5_correct_per_type = torch.zeros(self.num_img_types, device=self.device)\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for x_batch, y_batch, c_batch in self.test_batches:\n",
    "                x_batch, y_batch, c_batch = x_batch.to(self.device), y_batch.to(self.device), c_batch.to(self.device)\n",
    "                tokens = self.model(x_batch)\n",
    "                \n",
    "                if len(tokens) == 3 and self.head_strategy != 1:\n",
    "                    preds = (tokens[0] + tokens[1] + self.model.output_head.corrupt_connection(tokens[2])) / 3\n",
    "                else:\n",
    "                    preds = (tokens[0] + tokens[1]) / 2\n",
    "                    print(\"done preds!\")\n",
    "                \n",
    "                total_samples += y_batch.size(0)\n",
    "                # top-1 acc\n",
    "                top1_right = (torch.argmax(preds, dim=1) == y_batch)\n",
    "                top1_correct_preds += top1_right.sum().item()\n",
    "                # top-5 acc\n",
    "                top5_right = torch.topk(preds, 5, dim=1).indices.eq(y_batch.unsqueeze(1)).any(dim=1)\n",
    "                top5_correct_preds += top5_right.sum().item()\n",
    "                # ECE loss\n",
    "                total_ece += compute_ece(preds, y_batch, self.device) * y_batch.size(0)\n",
    "                # Per-type acc\n",
    "                for t in range(self.num_img_types):\n",
    "                    mask = (c_batch == t)\n",
    "                    total_per_type[t] += mask.sum()\n",
    "                    top1_correct_per_type[t] += top1_right[mask].sum()\n",
    "                    top5_correct_per_type[t] += top5_right[mask].sum()\n",
    "                # entropy\n",
    "                total_entropy += -torch.sum(torch.softmax(preds, dim=1) * torch.log_softmax(preds, dim=1), dim=1).sum().item()\n",
    "                # top-1 corruption classification acc\n",
    "                if len(tokens) == 3 : top1_correct_corrs += (torch.argmax(tokens[2], dim=1) == c_batch).sum().item()              \n",
    "\n",
    "        top1_acc_per_type = (top1_correct_per_type / total_per_type).tolist()\n",
    "        test_metrics = {\n",
    "            \"top1_acc\" : top1_correct_preds / total_samples, \n",
    "            \"top5_acc\" : top5_correct_preds / total_samples, \n",
    "            \"top1_acc_per_type\" : top1_acc_per_type,\n",
    "            \"top5_acc_per_type\" :(top5_correct_per_type / total_per_type).tolist(), \n",
    "            \"error_rate_per_type\" : [1 - acc for acc in top1_acc_per_type],\n",
    "            \"ece\" : total_ece / total_samples,\n",
    "            \"entropy\" : total_entropy / total_samples\n",
    "        }\n",
    "        if top1_correct_corrs : test_metrics[\"top1_corrupt_acc\"] = top1_correct_corrs / total_samples\n",
    "        if self.print_metrics : print(f\"Test-Accuracy:{test_metrics['top1_acc']:.2f}\")\n",
    "        return test_metrics\n",
    "\n",
    "    # ------------ training function ------------\n",
    "    def train_cdeit_model(self, optimizer, num_epochs=1):\n",
    "        self.model.train()\n",
    "        for epoch in range(1, num_epochs+1):\n",
    "            loss_total, loss_corrupt, loss_distill, loss_cls = 0, 0, 0, 0\n",
    "            total_samples, sim_cls_distill, sim_cls_corr = 0, 0, 0\n",
    "\n",
    "            print(f\"------- Epoch {epoch} -------\")\n",
    "            for x_batch, y_batch, c_batch in self.train_batches:\n",
    "                x_batch, y_batch, c_batch = x_batch.to(self.device), y_batch.to(self.device), c_batch.to(self.device)\n",
    "                tokens = self.model(x_batch)\n",
    "                \n",
    "                loss_calculater = LossCalculator(self.teacher_model)\n",
    "                L_corrupt = None\n",
    "                if len(tokens) == 3:\n",
    "                    L_total, L_cls, L_distill, L_corrupt = loss_calculater((third_batch, y_batch, c_batch), tokens)\n",
    "                else:\n",
    "                    L_total, L_cls, L_distill = loss_calculater((third_batch, y_batch), tokens)\n",
    "\n",
    "                # backprop\n",
    "                optimizer.zero_grad()\n",
    "                L_total.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                total_samples += y_batch.size(0)\n",
    "                # losses\n",
    "                loss_total += L_total.item() * y_batch.size(0)\n",
    "                loss_cls += L_cls.item() * y_batch.size(0)\n",
    "                loss_distill += L_distill.item() * y_batch.size(0)\n",
    "                if L_corrupt : loss_corrupt += L_corrupt.item() * y_batch.size(0)\n",
    "\n",
    "                # cosine similarity\n",
    "                sim_cls_distill += self.model.sim_cls_distill_end\n",
    "                sim_cls_corr += self.model.sim_cls_corr_end\n",
    "\n",
    "            train_metrics = {\n",
    "                \"loss_total\": loss_total/total_samples,\n",
    "                \"loss_cls\": loss_cls/total_samples,\n",
    "                \"loss_distill\": loss_distill/total_samples,\n",
    "                \"sim_cls_distill\" : sim_cls_distill/total_samples,\n",
    "                \"sim_cls_corr\" : sim_cls_corr/total_samples\n",
    "            }\n",
    "            if loss_corrupt : train_metrics[\"loss_corrupt\"] = loss_corrupt/total_samples\n",
    "            if self.print_metrics : print(f\"Train-Loss: {train_metrics['loss_total']:.3f}\")\n",
    "            test_metrics = self.test_cdeit_model()\n",
    "            self.all_train_metrics.append(train_metrics)\n",
    "            self.all_test_metrics.append(test_metrics)\n",
    "        \n",
    "        # save trained model\n",
    "        torch.save(self.model.state_dict(), self.save_path)\n",
    "        print(f\"\\nModel saved to {self.save_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
